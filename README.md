# Misinfo_Detection
The repository for the survey paper "Detecting Misinformation Act III: A Survey of Advances, Frontiers in AIGC Era"


## ðŸ“„ Paper List

### The Advances of MID with LLMs

#### LLMs with Content.

  * Towards Real-Time Fake News Detection under Evidence Scarcity. _Wei et al._ 2025. [[Paper](https://arxiv.org/abs/2510.11277)]
  * Step-by-Step Fact Verification System for Medical Claims with Explainable Reasoning. _Vladika et al._ 2025. [[Paper](https://aclanthology.org/2025.naacl-short.68/)]
  * PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation. _Modzelewski et al._ 2025.  [[Paper](https://aclanthology.org/2025.acl-long.1215/)]
  * FactGuard: Event-Centric and Commonsense-Guided Fake News Detection. _He et al._ 2025. [[Paper](https://arxiv.org/abs/2511.10281)]
  * Weakly supervised veracity classification with LLM-predicted credibility signals. _Leite et al._ 2025. [[Paper](https://link.springer.com/article/10.1140/epjds/s13688-025-00534-0)]
  * Improving the fact-checking performance of language models by relying on their entailment ability. _kumar et al._ 2025. [[Paper](https://arxiv.org/abs/2505.15050)]

#### LLMs with RAG.

  * HalluciNot: Hallucination Detection Through Context and Common Knowledge Verification. _Paudel et al._ 2025. [[Paper](https://arxiv.org/abs/2504.07069)]
  * FIRE: Fact-checking with iterative retrieval and verification. _Xie et al._ 2025. [[Paper](https://aclanthology.org/2025.findings-naacl.158/)]
  * +VeriRel: Verification feedback to enhance document retrieval for scientific fact checking. _Deng et al._ 2025. [[Paper](https://dl.acm.org/doi/10.1145/3746252.3760822)]
  * A dynamic knowledge update-driven model with large language models for fake news detection. _Jin et al._ 2025. [[Paper](https://arxiv.org/abs/2509.11687)]
  * When retrieval outperforms generation: Dense evidence retrieval for scalable fake news detection. _Qazi et al._ 2025. [[Paper](https://aclanthology.org/2025.ldk-1.26/)]
  * HiEAG: Evidence-Augmented Generation for Out-of-Context Misinformation Detection. _Wu et al._ 2025. [[Paper](https://arxiv.org/abs/2511.14027)]

### LLMs with Context.

  * Group-Adaptive Adversarial Learning for Robust Fake News Detection Against Malicious Comments. _Tong et al._ 2025. [[Paper](https://arxiv.org/abs/2510.09712)]
  * Limited effectiveness of llm-based data augmentation for covid-19 misinformation stance detection. _Choi et al._ 2025. [[Paper](https://arxiv.org/abs/2503.02328)]
  * Reasoning About the Unsaid: Misinformation Detection with Omission-Aware Graph Inference. _Wang et al._ 2025. [[Paper](https://arxiv.org/abs/2512.01728)]
  * Exploring Large Language Models for Effective Rumor Detection on Social Media. _Zeng et al._ 2025. [[Paper](https://aclanthology.org/2025.naacl-long.128/)]

### LLMs with Multi-modal.

  * SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection. _Qi et al._ 2024. [[Paper](https://openaccess.thecvf.com/content/CVPR2024/html/Qi_SNIFFER_Multimodal_Large_Language_Model_for_Explainable_Out-of-Context_Misinformation_Detection_CVPR_2024_paper.html)]
  * TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection. _Yan et al._ 2025. [[Paper](https://aclanthology.org/2025.emnlp-main.284.pdf)]
  * Guard Me If You Know Me: Protecting Specific Face-Identity from Deepfakes. _Lin et al._ 2025. [[Paper](https://arxiv.org/abs/2505.19582)]
  * Towards explainable fake image detection with multi-modal large language models. _Ji et al._ 2025. [[Paper](https://arxiv.org/abs/2504.14245)]

### The Frontier Challenges of MID
#### Detecting LLM-Generated Misinformation

  * Fake news in sheep's clothing: Robust fake news detection against LLM-empowered style attacks. _Wu et al._ 2024. [[Paper](https://dl.acm.org/doi/10.1145/3637528.3671804)]
  * Adversarial Style Augmentation via Large Language Model for Robust Fake News Detection. _Park et al._ 2025. [[Paper](https://dl.acm.org/doi/10.1145/3690134.3690184)]
  * RetrieverGuard: Empowering Information Retrieval to Combat LLM-Generated Misinformation. _Chen et al._ 2025. [[Paper](https://aclanthology.org/2025.findings-naacl.289/)]
  * Zero-knowledge LLM hallucination detection and mitigation through fine-grained cross-model consistency. _Goel et al._ 2025. [[Paper](https://aclanthology.org/2025.emnlp-industry.139/)]
  * ReEval: Automatic Hallucination Evaluation for Retrieval-Augmented Large Language Models via Transferable Adversarial Attacks. _Yu et al._ 2024. [[Paper](https://aclanthology.org/2024.findings-naacl.85/)]
  * Consistency Is the Key: Detecting Hallucinations in LLM Generated Text By Checking Inconsistencies About Key Facts. _Gupta et al._ 2025. [[Paper](https://arxiv.org/abs/2511.12236)]

#### Detecting Deepfake Content

  * Veritas: Generalizable deepfake detection via pattern-aware reasoning. _Tan et al._ 2025. [[Paper](https://arxiv.org/abs/2508.21048)]
  * TruthLens: Explainable DeepFake Detection for Face Manipulated and Fully Synthetic Data. _Kundu et al._ 2025. [[Paper](https://arxiv.org/abs/2503.15867)]
  * BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation. _Wen et al._ 2025. [[Paper](https://arxiv.org/abs/2505.12620)]
  * CAD: A General Multimodal Framework for Video Deepfake Detection via Cross-Modal Alignment and Distillation. _Du et al._ 2025. [[Paper](https://arxiv.org/abs/2505.15233)]
  * FakeShield: Explainable Image Forgery Detection and Localization via Multi-modal Large Language Models. _Xu et al._ 2024. [[Paper](https://arxiv.org/abs/2410.02761)]
  * Spot the fake: Large multimodal model-based synthetic image detection with artifact explanation. _Wen et al._ 2025. [[Paper](https://arxiv.org/abs/2503.14905)]

#### Detecting AI-Generated Text

  * A survey of ai-generated text forensic systems: Detection, attribution, and characterization. _Kumarage et al._ 2024. [[Paper](https://arxiv.org/abs/2403.01152)]
  * The science of detecting LLM-generated text. _Tang et al._ 2024. [[Paper](https://dl.acm.org/doi/10.1145/3649466)]
  * Biscope: Ai-generated text detection by checking memorization of preceding tokens. _Guo et al._ 2024. [[Paper](https://proceedings.neurips.cc/paper_files/paper/2024/hash/bea4e2a9792070d6a892787df9240409-Abstract-Conference.html)]
  * Deep kernel relative test for machine-generated text detection. _Song et al._ 2025. [[Paper](https://openreview.net/forum?id=uCa1wN1R4A)]
  * DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm. _Zhu et al._ 2025. [[Paper](https://openreview.net/forum?id=yQoHUijSHx)]
  * Detecting machine-generated texts by multi-population aware optimization for maximum mean discrepancy. _Zhang et al._ 2024. [[Paper](https://arxiv.org/abs/2402.16041)]

### Future Direction
#### Agentic Detection System

  * Exclaim: An explainable cross-modal agentic system for misinformation detection with hierarchical retrieval. _Wu et al._ 2025. [[Paper](https://arxiv.org/abs/2504.06269)]
  * The truth becomes clearer through debate! Multi-Agent Systems with Large Language Models Unmask Fake News. _Liu et al._ 2025. [[Paper](https://dl.acm.org/doi/10.1145/3719721.3719770)]
  * DeepEyes: Incentivizing "Thinking with Images" via Reinforcement Learning. _Zheng et al._ 2025. [[Paper](https://arxiv.org/abs/2505.14362)]

#### Omni-modal Deepfake

  * RAMA: Retrieval-Augmented Multi-Agent Framework for Misinformation Detection in Multimodal Fact-Checking. _Yang et al._ 2025. [[Paper](https://arxiv.org/abs/2507.09174)]
  * EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning. _Sun et al._ 2025. [[Paper](https://arxiv.org/abs/2510.16442)]
  * TriDF: Evaluating Perception, Detection, and Hallucination for Interpretable DeepFake Detection. _Jiang-Lin et al._ 2025. [[Paper](https://arxiv.org/abs/2512.10652)]

#### Facing the Evolution of LLMs

  * Beyond human data: Aligning multimodal large language models by iterative self-evolution. _Tan et al._ 2025. [[Paper](https://ojs.aaai.org/index.php/AAAI/article/view/30932)]
  * MPCG: Multi-Round Persona-Conditioned Generation for Modeling the Evolution of Misinformation with LLMs. _Brian et al._ 2025. [[Paper](https://aclanthology.org/2025.emnlp-main.1631/)]
